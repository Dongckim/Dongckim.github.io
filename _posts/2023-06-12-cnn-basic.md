---
layout: post
title:  "CNN 기초와 구성"
date:   2023-06-12
featured_image: keras.png
tags: [Deep-Learning]
---
### 이 이미지는 신발/상의/하의/가방 중 어떤 것인지 구분하는 딥러닝 모델을 만들어보자.
- 뉴럴 네트워크에 집어넣을 수 있는 것은 무조건 숫자임.
- 그렇기 때문에 이미지의 픽셀(pixel)데이터는 숫자로 표현 가능
- 하나의 노드(input)에 픽셀 정보가 들어가서 이미지 데이터를 입력 받을 수 있음
```
import ssl
ssl._create_default_https_context = ssl._create_unverified_context

import tensorflow as tf
import matplotlib.pyplot as plt

(trainX, trainY),(testX, testY) = tf.keras.datasets.fashion_mnist.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', ' Shirt', 'Sneaker', 'Bag', 'Ankleboot']

model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, input_shape=(28, 28), activation='relu'), #input_shape=(여러개의 데이터 셋안에서 데이터 하나의 모양을 넣어주면 됨)
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Flatten(),  #2차원데이터를 1차원으로 압축시키고 싶을 때 쓰는 레이어
    tf.keras.layers.Dense(10, activation='softmax'),
])

model.compile( loss = "sparse_categorical_crossentropy", optimizer = 'adam', metrics=['accuracy'])
model.fit(trainX, trainY, epochs = 5)

print(model.predict(testY))
```
- 결과를 0-1로 압축시키기 위해, sigmoid는 이지선다 binary + node 1개로 보통 지정한다. 
- softmax 카테고리 예측문제에 사용 + 카테고리 갯수 + 예측한 갯수의 확률 다 더하면 1이 나옴.

#### 이미지를 파이썬으로 띄워보는 법 (matplotlib.pyplot)
```
# plt.imshow(trainX[1])
# plt.gray()
# plt.show()
```

### 이미지 데이터를 flatten 하는 것의 문제점
→ flatten() 레이어는 해당 이미지 데이터들을 해체해서 딥러닝을 돌리는 짓을 일컫는다.
→ 이렇게하면 예측모델의 응용력도 없어지기 마련이다.
(똑같은 모양도, 픽셀의 위치가 바뀌어지면 가중치들을 다시 찾아내야하는 상황이 생김. 똑같이 생긴건데 왜?)

### Convolutional Layer
1. 이미지에서 중요한 정보를 추려서 복사본 20장을 만든다.
2. 그곳에 이미지의 중요한 feature, 특성이 담겨있다.
3. 이걸 feature extraction을 한다.
4. convolutional Layer로 feature extraction을 한다. → 이미지의 복사본 20장을 이미지의 특성들이 각각 다르게 강조되게 ㄱㄱ

### Kernel
![퍼셉트론 이해 그림](http://blog.geveo.com/img/hk_3_2021_12_16.png)
- Tensorflow는 여러가지 커널들을 자동적용해서 레이어(Conv2D)를 만들어준다.
- 특징이 강조된 다양한 커널들을 보고, 뉴럴 네트워크가 보고 학습하게 됨.(창문, 기둥)

### 단순 Convolution의 문제점 : feature의 위치
ex) 중요한 wheel feature를 감지했다. -> 자동차일 확률 98% -> (똑같은 자동차의 위치가 조정된 사진)wheel feature가 없네요 그러므로 자동자일 확률 10%
=> Conolutional + Pooling Layer을 도입하면, 특징추출 + 특징을 가운데로 모아줘서 위치가 조정되어도 똑같이 확인됨(translation invariance)

### CNN(Convolutional Neural Network) 순서
1. Input Image
2. Filters
3. Convolution Layers
4. Pooling
5. Flattening

### Convolutional Layer 도입
```
#위 내용 동일
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32,(3,3), padding='same', activation = 'relu', input_shape = (28,28,1)) #(32개의 feature, (커널사이즈))
    #tf.keras.layers.Dense(128, input_shape=(28, 28), activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Flatten(),  #2차원데이터를 1차원으로 압축시키고 싶을 때 쓰는 레이어
    tf.keras.layers.Dense(10, activation='softmax'),
])
```
- 위 Conv2D에서 relu 활성함수를 쓴 이유는
- 이미지를 숫자로 바꾸면 0~255 사이임, 이미지는 음수 값이 없기 때문에, 혹시 음수가 나오면, 다 0 으로 맞춰주는 relu 활성함수를 사용함.
- input_shape()를 항상 첫번때 레이어에 맞춰주어야하는데, 이때 ndim에러를 만날 수 있는데, 이는 Conv2D레이어는 4차원 데이터가 필요하기 때문이다
- 기존 데이터들은 [R, G, B] 하나의 차원으로 묶여 있기 때문에 3차원 데이터로 인식하므로,
- [[R],[G],[B]]이런식으로 하나의 차원을 더 만들어서 형태를 만들어주어야한다 (reshape)
```
import numpy as np
(trainX, trainY),(testX, testY) = tf.keras.datasets.fashion_mnist.load_data()

trainX.reshape((trainX.shape[0]), 28, 28, 1)
testX.reshape(testX.shape[0], 28, 28, 1)
```
- Convolutional Layer 작업이 끝난 후엔, 사이즈를 줄여주면서 이미지의 중요한 포인트들을 가운데로 모으는 작업이 진행되어야 함(MaxPooling2D)
```
#위 내용 동일
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32,(3,3), padding='same', activation = 'relu', input_shape = (28,28,1)) #(32개의 feature, (커널사이즈))
    tf.keras.layers.MaxPooling2D((2,2))
    tf.keras.layers.Flatten(),  #2차원데이터를 1차원으로 압축시키고 싶을 때 쓰는 레이어
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax'),
])
model.compile( loss = "sparse_categorical_crossentropy", optimizer = 'adam', metrics=['accuracy'])
model.fit(trainX, trainY, epochs = 5)

score = model.evaluate(testX, testY)
print(score)
```
- Flatten - Dense - 출력 순서를 지켜주어야 함.
- Conv2D + MaxPooling2D 는 세트로 여러번 해도 상관없음.
- 이 때 Epoch을 거칠 수록, accuracy 값은 꾸준히 향상됨.
- 그러나, 새로운 테스트 데이터로 학습된 모델을 평가하면, 가장 마지막 epoch의 accuracy보다 덜 나올 수 밖에 없는데, 이는 Overfitting현상이라고 한다.
- overfitting이란, 학습된 데이터의 답안을 외워버렸기 때문에, accuracy자체만 높인 현상이다

### overfitting 현상 방지하기
```
#위와 동일
model.compile( loss = "sparse_categorical_crossentropy", optimizer = 'adam', metrics=['accuracy'])
model.fit(trainX, trainY, validation_data = (testX, testY) epochs = 5)

<!--score = model.evaluate(testX, testY)-->
<!--print(score)-->
```
-epoch 1회가 끝날 때마다 evaluation진행하기 때문에, overfitting이 되기 전에 결과값을 도출해낼 수 있다.
-validation_accuracy를 더 높일 수 있는 방법을 생각해보자. (Dense Layer?, Conv+MaxPooling?)